## ETL com IPCA e Commodity Boi Gordo (Arquitetura Medallion - Delta Lake)

# ğŸ“Š ETL de IPCA e Boi Gordo

![Python](https://img.shields.io/badge/python-3.10+-blue)
![Spark](https://img.shields.io/badge/spark-pyspark-orange)
![Delta Lake](https://img.shields.io/badge/delta-lake-+lightblue)
![Status](https://img.shields.io/badge/status-professional-green)

*Pipeline ETL desenvolvido para ingestÃ£o, padronizaÃ§Ã£o e versionamento de dados econÃ´micos (IPCA e Boi Gordo), utilizando **Apache Spark**, **Delta Lake** e **Python** em ambiente local (Windows).*

---

## ğŸ—‚ï¸ Estrutura do Projeto

```text
etl-ipca-boi-gordo/
â”‚
â”œâ”€â”€ data_source/
â”‚     â”œâ”€â”€ csv/                     # Arquivos brutos (.json)
â”‚     â””â”€â”€ xls/                     # Arquivos brutos (.xls)
â”‚
â”œâ”€â”€ docs/     
â”‚
â”œâ”€â”€ lakehouse/
|     |  â””â”€â”€ bronze/               # Tabelas Delta (Camada Bronze)
|     |        â””â”€â”€ boi_gordo/
|     |        â””â”€â”€ IPCA/               
â”‚     â”œâ”€â”€ Silver/                  # Tabelas Delta ( Silver Transformations )
|     |      â””â”€â”€ boi_gordo/
|     |      â””â”€â”€ IPCA/
|     |                        
â”‚     â””â”€â”€ Gold/                    # Tabelas Delta (Gold Analytics)
|           â””â”€â”€ analitico/
â”‚           â””â”€â”€ boi_ipca/
|           â””â”€â”€ insights/
|
â”œâ”€â”€ Notebooks/
|        â””â”€â”€ 01_validacao_bronze.ipynb
|        â””â”€â”€ 02_transform_silver.ipynb
|        â””â”€â”€ 03_analytics_gold.ipynb
â”œâ”€â”€ src/
â”‚    â”‚
â”‚    â””â”€â”€ bronze/
â”‚           â”œâ”€â”€ ingest_bronze_delta.py 
â”‚           â””â”€â”€ ingest_ipca_bcb_bronze_delta.py
â”‚           â””â”€â”€ ingest_xls.py
|
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Compatibilidade de VersÃµes â€” Apache Spark

*Este documento descreve as **versÃµes recomendadas e compatÃ­veis** para executar o Apache Spark de forma estÃ¡vel, especialmente em ambientes Windows com Python (ETL / Data Engineering).*

---

### VersÃµes Recomendadas (Stack EstÃ¡vel)

### Java (ObrigatÃ³rio)

*O Apache Spark **depende diretamente da JVM**. Nem toda versÃ£o do Java Ã© compatÃ­vel.*

| Java | Status | ObservaÃ§Ãµes |
|-----|-------|-------------|
| Java 11 (LTS) | Recomendado | Mais usado em produÃ§Ã£o |
| Java 17 (LTS) | Recomendado | CompatÃ­vel e estÃ¡vel |
| Java 8 | Legado | Funciona, mas nÃ£o recomendado para novos projetos |
| Java 21+ | NÃ£o suportado | Pode falhar silenciosamente |
| Java 25 (LTS) | IncompatÃ­vel | Spark trava ao iniciar (sem erro claro) |

ğŸ“Œ **RecomendaÃ§Ã£o oficial**:  
> Use **Java 11 ou Java 17** para evitar travamentos na inicializaÃ§Ã£o do Spark.

---

### ğŸ Python (PySpark)

| Python | Status |
|------|--------|
| Python 3.9 | Suportado |
| Python 3.10 |  Recomendado |
| Python 3.11 |  Parcial |
| Python 3.12 |  Problemas frequentes |

ğŸ“Œ **RecomendaÃ§Ã£o**:  
> Utilize **Python 3.10** para mÃ¡xima compatibilidade com PySpark, Pandas e PyArrow.

---

## âš¡ Apache Spark

| Spark | Java CompatÃ­vel |
|------|----------------|
| Spark 3.4.x | Java 8, 11, 17 |
| Spark 3.5.x | Java 11, 17 |

---

ğŸ“Œ Spark **nÃ£o estÃ¡ preparado** para Java â‰¥ que a versÃ£o 21 no momento.

---

### ğŸ§± Stack Recomendada para ETL (Bronze / Silver / Gold)

```
Python 3.10
Java 17 (LTS)
Apache Spark 3.5.x
Delta-spark 3.5.1
Conda / venv
Windows ou Linux
```
### Pipeline de ingestÃ£o de dados XLS -> CSV

```
etl-ipca-boi-gordo/
â”‚
â”œâ”€â”€ data_source/
â”‚   â””â”€â”€ xls/
â”‚       â””â”€â”€ cepea-consulta-20260131203157.xls
â”‚
â”œâ”€â”€ ingest_xls.py   


data_source/
â”œâ”€â”€ xls/
â”‚   â””â”€â”€ cepea-consulta-20260131203157.xls
â”‚
â””â”€â”€ csv/
    â”œâ”€â”€ cepea-consulta-20260131203157.csv
    â””â”€â”€ _manifest.csv
```

O `_manifest.csv` vai registrar:

- hash do arquivo
- nome do XLS original
- CSV gerado
- timestamp UTC

> Se vocÃª rodar de novo, ele nÃ£o reconverte o mesmo arquivo (dedupe por hash)

Para execuÃ§Ã£o: 

`python src\bronze\ingest_xls.py`


## Pipeline inicial (extraÃ§Ã£o â†’ transformaÃ§Ã£o â†’ pronto para Bronze)

### 1) ExtraÃ§Ã£o (landing / data_source/xls)
- Objetivo: coletar os arquivos `.xls/.xlsx` brutos exatamente como chegam da fonte (sem alterar conteÃºdo).
- Local: `data_source/xls/`
- BenefÃ­cio: mantÃ©m o â€œdado originalâ€ para auditoria e reprocessamentos.

---

### 2) TransformaÃ§Ã£o canÃ´nica (XLS â†’ CSV padronizado)
- O script lÃª a primeira planilha do XLS e mantÃ©m apenas as **2 primeiras colunas** (data e valor).
- Remove linhas de cabeÃ§alho/observaÃ§Ã£o (â€œlinhas lixoâ€) e padroniza o dataset para um formato Ãºnico:
  - `mes_ano` no padrÃ£o `MM/YYYY`
  - `valor` como nÃºmero (`float`), normalizando pt-BR (ex.: `1.234,56` â†’ `1234.56`)
- SaÃ­da gerada em: `data_source/csv/<nome_do_arquivo>.csv`

**Estrutura final do CSV:**
- `mes_ano` (string `MM/YYYY`)
- `valor` (float)

---

### 3) Controle de ingestÃ£o (dedupe por hash + manifest)
- Antes de converter, o pipeline calcula o **SHA-256** do arquivo XLS.
- Se o hash jÃ¡ existir no `_manifest.csv`, o arquivo Ã© ignorado (evita reconversÃ£o e duplicidade).
- Se for novo, converte e registra no manifest:

Arquivo: `data_source/csv/_manifest.csv` registra:
- `file_hash` (sha256 do XLS/XLSX)
- `source_file` (nome original do XLS)
- `csv_file` (CSV gerado)
- `converted_at_utc` (timestamp UTC)

---

### 4) Pronto para a camada Bronze (Spark + Delta)

- Resultado: CSVs **limpos e padronizados** em `data_source/csv/`, ideais para leitura no Spark.
- PrÃ³ximo passo (Bronze): o Spark lÃª esses CSVs e grava em Delta adicionando colunas tÃ©cnicas, por exemplo:
  - `source_file` (origem do dado)
  - `file_hash` (chave de dedupe/linhagem)
  - `ingested_at` (timestamp de ingestÃ£o)
> Assim, a Bronze fica rastreÃ¡vel, reprocessÃ¡vel e com linhagem completa.


## Pipeline Bronze (Delta Lake)

```ingest_bronze_delta.py```

### Objetivo:

Ingerir os dados **CSV** (`data_source/csv`) para a **camada Bronze** do lakehouse em **formato Delta**, garantindo rastreabilidade, idempotÃªncia e base sÃ³lida para Silver/Gold na arquitetura medalhÃ£o.

---

### Papel na arquitetura medalhÃ£o:

- **Data Source**: dados jÃ¡ normalizados (CSV).
- **Bronze (este arquivo)**: persistÃªncia confiÃ¡vel em Delta, com histÃ³rico e linhagem.
- **Silver/Gold**: camadas futuras para regras de negÃ³cio e agregaÃ§Ãµes.

---

## Fluxo do pipeline

1. **InicializaÃ§Ã£o do Spark**
   - Cria `SparkSession` com **Delta Lake habilitado** (`configure_spark_with_delta_pip`).
   - Define timezone UTC e configs bÃ¡sicas de execuÃ§Ã£o.

2. **Leitura do manifest**
   - LÃª `_manifest.csv`, que registra:
     - `file_hash`, `source_file`, `csv_file`, `converted_at_utc`
   - O manifest Ã© a fonte de verdade para **controle de ingestÃ£o**.

3. **IdempotÃªncia por hash**
   - Verifica se a tabela Delta Bronze jÃ¡ existe.
   - Compara os `file_hash` do manifest com os jÃ¡ presentes na Bronze.
   - SÃ³ processa arquivos **ainda nÃ£o ingeridos**.

4. **Leitura dos CSVs**
   - LÃª todos os CSVs novos de uma vez, com **schema explÃ­cito**.
   - Evita inferÃªncia instÃ¡vel de tipos.

5. **Enriquecimento com linhagem**
   - Faz join com o manifest para adicionar:
     - `source_file`
     - `file_hash`
     - `converted_at_utc`
   - Acrescenta colunas tÃ©cnicas:
     - `ingest_run_id`
     - `ingested_at_utc`

6. **DerivaÃ§Ã£o de partiÃ§Ãµes**
   - Extrai `ano` e `mes` a partir de `mes_ano`.
   - Usadas para **partitioning** da tabela Delta.

7. **Checagens de qualidade mÃ­nimas**
   - Valida formato de `mes_ano` (`MM/YYYY`).
   - Garante que colunas de linhagem nÃ£o sejam nulas.
   - Bronze aceita imperfeiÃ§Ãµes, mas nÃ£o aceita â€œlixoâ€.

8. **GravaÃ§Ã£o na Bronze (Delta)**
   - Remove duplicidades defensivas (`mes_ano + file_hash`).
   - Escreve em modo `append` no path da tabela Delta.
   - Particiona por `ano` e `mes`.

---

## Resultado final:
- Tabela Delta em: `lakehouse/bronze/boi_gordo/`

> Com:

- HistÃ³rico completo
- Linhagem por arquivo
- IdempotÃªncia garantida
- Pronta para consumo pela camada Silver

---

## BenefÃ­cios de engenharia:

- Evita reprocessamento acidental
- Facilita auditoria e reprocessos
- Isola instabilidades da fonte
- Escala naturalmente para novos datasets (IPCA, boi gordo, etc.)

Este arquivo Ã© o **pilar da camada Bronze** do projeto.

```
lakehouse/
â””â”€â”€ bronze/
    â””â”€â”€ boi_gordo/
        â”œâ”€â”€ _delta_log/
        â””â”€â”€ ano=2025/
            â”œâ”€â”€ mes=01/
            â”œâ”€â”€ mes=02/
            â””â”€â”€ ...


- Dessa forma temos o Delta Lake estÃ¡ corretamente habilitado.
- Particionada por ano e mÃªs.
- O pipeline idempotente (rodar de novo nÃ£o duplica)
- Design estÃ¡ alinhado Ã  arquitetura medalhÃ£o
 ```           

## IngestÃ£o Bronze â€” Pipeline IPCA (BCB/SGS) em Delta Lake

O script (`src/bronze/ingest_ipca_bcb_bronze_delta.py`) extrai o IPCA diretamente da API pÃºblica do Banco Central (SGS) e grava os dados na camada **Bronze** do lakehouse em **formato Delta**, seguindo o padrÃ£o da arquitetura medalhÃ£o (Bronze â†’ Silver â†’ Gold).

### O que ele faz:

- Faz **fetch** da sÃ©rie do IPCA via API BCB/SGS (por `SERIES_ID` e intervalo de datas).
- Converte e tipa os campos:
  - `data_ref` (date)
  - `valor` (double)
- Adiciona colunas tÃ©cnicas de **linhagem/auditoria** (`source`, `series_id`, `request_url`, `ingest_run_id`, `ingested_at_utc`).
- Aplica **idempotÃªncia** via `payload_hash` (SHA-256 do payload retornado): se o mesmo conteÃºdo jÃ¡ foi ingerido, nÃ£o reprocessa.
- Grava em **Delta Lake** com partiÃ§Ã£o por `ano` e `mes`:
  - `lakehouse/bronze/ipca/_delta_log`
  - `lakehouse/bronze/ipca/ano=YYYY/mes=MM`

### PrÃ©-requisitos:

- Ambiente Python ativo (ex.: `conda activate env_ipca_boi_2`)
- DependÃªncias instaladas: `pyspark` e `delta-spark` (**VersÃµes especÃ­ficas**)

### ExecuÃ§Ã£o:

Na raiz do projeto:

```
python src/bronze/ingest_ipca_bcb_bronze_delta.py
```

## Fonte de Dados â€“ CEPEA (Contexto TÃ©cnico e DecisÃ£o de Engenharia)

Os dados de preÃ§o do boi gordo utilizados neste projeto tÃªm como fonte a **CEPEA/USP** (Centro de Estudos AvanÃ§ados em Economia Aplicada), uma instituiÃ§Ã£o acadÃªmica amplamente reconhecida no Brasil.

Entretanto, a CEPEA nÃ£o disponibiliza uma API pÃºblica para consumo automatizado de seus dados. O acesso Ã© voltado prioritariamente ao consumo humano via navegador, com disponibilizaÃ§Ã£o controlada de arquivos (ex.: XLS).

## ğŸ›ï¸ Fonte oficial

InstituiÃ§Ã£o: Banco Central do Brasil
API: SGS
SÃ©rie IPCA mensal (%): 433
Endpoint com filtro por data:

https://api.bcb.gov.br/dados/serie/bcdata.sgs.433/dados


## Mecanismos de SeguranÃ§a do Site da CEPEA

O site da CEPEA utiliza mecanismos modernos de proteÃ§Ã£o contra automaÃ§Ãµes, muito provavelmente baseados em soluÃ§Ãµes como `Cloudflare` ou WAFs equivalentes. Entre os mecanismos observados:

 - Web Application Firewall (WAF)
 - Bloqueio de requisiÃ§Ãµes automatizadas
 - AnÃ¡lise de headers HTTP e User-Agent
 - RestriÃ§Ãµes a acessos diretos a endpoints internos
 - Bot Management (Anti-Bot)
 - ExecuÃ§Ã£o de desafios JavaScript invisÃ­veis
 - Uso de cookies e tokens de sessÃ£o dinÃ¢micos
 - ValidaÃ§Ã£o do comportamento de navegaÃ§Ã£o
 - DetecÃ§Ã£o Comportamental
 - AnÃ¡lise de frequÃªncia e padrÃ£o de acessos
 - IdentificaÃ§Ã£o de fluxos nÃ£o-humanos
 - Bloqueios silenciosos apÃ³s mÃºltiplas tentativas
 - Rate Limiting e Fingerprinting
 - LimitaÃ§Ã£o por IP
 - DetecÃ§Ã£o de padrÃµes repetitivos
 - Bloqueio progressivo de automaÃ§Ãµes

Esses mecanismos tornam inviÃ¡vel a extraÃ§Ã£o confiÃ¡vel e contÃ­nua de dados via scraping tradicional.

### Tentativas TÃ©cnicas Avaliadas

Antes da definiÃ§Ã£o da arquitetura final, foram consideradas e avaliadas as seguintes abordagens:

 - RequisiÃ§Ãµes HTTP diretas (requests, curl)
 -  Retorno de HTML incompleto ou pÃ¡ginas de desafio
 - Bloqueios intermitentes (403)
 - Falha em resolver desafios JavaScript
 - SimulaÃ§Ã£o de navegador (headers customizados)
 - Funciona apenas em acessos isolados
 - Falha em execuÃ§Ãµes recorrentes
 - Cookies e tokens expiram rapidamente
 - AutomaÃ§Ã£o de navegador (Selenium / Playwright)
 - Alto custo operacional
 - ExecuÃ§Ã£o instÃ¡vel em pipelines
 - Bloqueios por fingerprint e comportamento
 - NÃ£o escalÃ¡vel nem confiÃ¡vel
 - Engenharia reversa de chamadas internas
 - DependÃªncia de tokens de sessÃ£o
 - Headers dinÃ¢micos
 
> Nenhuma dessas abordagens atende aos requisitos de estabilidade, escalabilidade, manutenÃ§Ã£o e governanÃ§a exigidos para um pipeline de dados confiÃ¡vel.

```Diante desse cenÃ¡rio, a CEPEA foi tratada como uma fonte legada protegida.```

A estratÃ©gia adotada foi utilizar o arquivo XLS oficialmente disponibilizado pela CEPEA como ponto de entrada do pipeline e evitar scraping e automaÃ§Ãµes frÃ¡geis. Dessa forma, priorizei a  fidelidade, reprodutibilidade e conformidade dos dados. O arquivo XLS representa o primeiro ponto confiÃ¡vel do dado.



### ğŸ“Š Camada Gold â€” Modelo EconÃ´mico (IPCA Ã— Boi Gordo)
> 1. Objetivo da Camada Gold

A camada Gold representa o nÃ­vel mais alto de refinamento do lakehouse, destinada ao consumo analÃ­tico direto.
Ela consolida, enriquece e interpreta dados econÃ´micos provenientes das camadas Silver, aplicando regras de negÃ³cio explÃ­citas e mÃ©tricas derivadas.

### Neste projeto, a Gold tem como objetivo:

- Comparar a inflaÃ§Ã£o (IPCA) com o preÃ§o do boi gordo
- Calcular variaÃ§Ãµes mensais
- Identificar divergÃªncias econÃ´micas
- Produzir um dataset pronto para dashboards, relatÃ³rios e anÃ¡lises exploratÃ³rias

```
A camada Gold nÃ£o recebe dados externos.
Ela depende exclusivamente das tabelas Silver jÃ¡ validadas.
```

3. Fontes de Dados (Camada Silver)


| Database |	Tabela |	DescriÃ§Ã£o |
|------|--------| --- |
 silver	| silver.ipca| 	IPCA mensal normalizado |
 silver | 	silver.boi_gordo |	PreÃ§o mensal do boi gordo |

## GrÃ£o dos dados:

### Mensal:

> 1 registro por mÃªs

> Chave temporal :
data (DATE, sempre o primeiro dia do mÃªs â€” YYYY-MM-01)

> Chave de JunÃ§Ã£o
data (DATE)

> Tipo de Join: INNER JOIN
 - Apenas meses presentes em ambas as sÃ©ries (IPCA e Boi) sÃ£o considerados.

```Essa decisÃ£o garante comparabilidade direta, e ausÃªncia de valores artificiais e integridade analÃ­tica```

## Estrutura da Camada Gold:

A camada Gold Ã© composta por:

- Tabela intermediÃ¡ria: gold.insights
- Tabela analÃ­tica final: gold.analitico
- View oficial de consumo: gold.vw_gold_dashboard

### Tabela gold.insights
### DescriÃ§Ã£o

A Tabela intermediÃ¡ria contÃ©m os valores base e as variaÃ§Ãµes mensais calculadas a partir de funÃ§Ãµes de janela ```(lag).```

> Ela serve como base para regras analÃ­ticas mais complexas.

```Schema:```

Coluna |	Tipo |	DescriÃ§Ã£o |
------ | -----|----|
data	| date |	Data de referÃªncia mensal
ano	|int	| Ano
mes	| int	| MÃªs
boi_gordo|	double	|PreÃ§o do boi gordo
ipca|	double|	IPCA mensal
variacao_boi|	double|	VariaÃ§Ã£o percentual mensal do boi
variacao_ipca	|double|	VariaÃ§Ã£o percentual mensal do IPCA

## Regras de CÃ¡lculo:

### VariaÃ§Ã£o mensal do boi_gordo:

```variacao_boi =```
((boi_gordo_atual - boi_gordo_anterior) / boi_gordo_anterior) * 100


### VariaÃ§Ã£o mensal do IPCA:

```variacao_ipca = ```
((ipca_atual - ipca_anterior) / ipca_anterior) * 100


O valor anterior Ã© obtido via ```lag()``` ordenado pela coluna data.

## Tabela gold.analitico:

> DescriÃ§Ã£o

Tabela final da camada Gold, projetada para dashboards e anÃ¡lises econÃ´micas.

AlÃ©m das variaÃ§Ãµes mensais, ela inclui as classificaÃ§Ãµes qualitativas, mÃ©tricas globais e indicadores comparativos

```Schema```

Coluna|	Tipo	|DescriÃ§Ã£o|
--|---|--|
data	|date|	Data de referÃªncia
boi_gordo|	double|	PreÃ§o do boi
ipca	|double|	IPCA mensal
variacao_boi|	double|	VariaÃ§Ã£o mensal do boi (%)
variacao_ipca	|double|	VariaÃ§Ã£o mensal do IPCA (%)
media_variacoes	|double|	MÃ©dia entre variaÃ§Ã£o do boi e do IPCA
destaque|	string	|SÃ©rie com maior crescimento
classe_impacto|	string|	Grau de divergÃªncia
correlacao_global	|double|	CorrelaÃ§Ã£o global IPCA Ã— Boi
media_ipca_global	|double|	MÃ©dia global da variaÃ§Ã£o do IPCA
media_boi_global	|double|	MÃ©dia global da variaÃ§Ã£o do boi
media_combinada_global|	double|	MÃ©dia combinada global

## Regras de NegÃ³cio:

### Coluna destaque:

Identifica qual indicador cresceu mais no mÃªs.

Se a ```variacao_boi``` > ```variacao_ipca``` â†’ ```"PreÃ§o do boi cresce mais"```

Se ```variacao_ipca``` > ```variacao_boi```  â†’ ```"InflaÃ§Ã£o cresce mais"```

Caso contrÃ¡rio â†’ ```"Empate"```

## Coluna classe_impacto

Classifica a diferenÃ§a absoluta entre as variaÃ§Ãµes.

```
DiferenÃ§a > 5%        â†’ Alta divergÃªncia
DiferenÃ§a entre 2â€“5%  â†’ MÃ©dia divergÃªncia
DiferenÃ§a < 2%        â†’ Baixa divergÃªncia
```
## MÃ©tricas Globais:

As mÃ©tricas globais sÃ£o calculadas uma Ãºnica vez e replicadas em todas as linhas para facilitar consumo em ferramentas de BI.

**MÃ©tricas incluÃ­das:**

CorrelaÃ§Ã£o entre ```variacao_ipca``` e ```variacao_boi```

 - MÃ©dia global da variaÃ§Ã£o do IPCA
 - MÃ©dia global da variaÃ§Ã£o do boi
 - MÃ©dia combinada das duas sÃ©ries

## View Oficial de Consumo:
```
View: gold.vw_gold_dashboard
SELECT *
FROM gold.analitico
```

Esta view Ã© o ponto Ãºnico de acesso recomendado para dashboards
consultas exploratÃ³rias e integraÃ§Ãµes externas

Dessa forma a camada Gold garante:

- GrÃ£o temporal Ãºnico (mensal)
- Chave de junÃ§Ã£o consistente
- Dados conformados
- Regras de negÃ³cio explÃ­citas
- Total independÃªncia de Databricks
- Compatibilidade com Spark local + Delta Lake

## PossÃ­veis EvoluÃ§Ãµes Futuras:

 - Deflacionamento do preÃ§o do boi pelo IPCA
 - InclusÃ£o de novas sÃ©ries econÃ´micas
 - AgregaÃ§Ãµes trimestrais e anuais
 - Indicadores de tendÃªncia e volatilidade
 - CÃ¡lculo de correlaÃ§Ãµes mÃ³veis

> A camada Gold sintetiza o valor do projeto ao transformar dados econÃ´micos brutos em insights acionÃ¡veis, mantendo rastreabilidade, clareza e escalabilidade.

## ğŸ› ï¸ Ferramentas Utilizadas

### Apache Spark
Framework de processamento distribuÃ­do em larga escala, utilizado como motor principal de processamento de dados do projeto.  
Permite leitura, transformaÃ§Ã£o e escrita eficiente de grandes volumes de dados.

- Site oficial: https://spark.apache.org/
- Linguagem utilizada: **PySpark (Python)**

---

### Delta Lake
Camada de armazenamento transacional sobre arquivos Parquet, usada na **camada Bronze** para garantir:
- ACID transactions  
- Versionamento de dados  
- Controle de schema  
- Reprocessamentos seguros  

- Site oficial: https://delta.io/

---

### Pandas
Biblioteca Python utilizada no prÃ©-processamento dos arquivos `.xls`, especialmente para:
- Leitura de planilhas Excel  
- PadronizaÃ§Ã£o de nomes de colunas  
- ConversÃ£o inicial para Parquet  

- DocumentaÃ§Ã£o: https://pandas.pydata.org/docs/

---

### Parquet
Formato de arquivo colunar otimizado para analytics, usado como padrÃ£o de armazenamento intermediÃ¡rio e final.

- EspecificaÃ§Ã£o: https://parquet.apache.org/

---

### Python
Linguagem principal do projeto, responsÃ¡vel por:
- OrquestraÃ§Ã£o do pipeline ETL  
- ManipulaÃ§Ã£o de arquivos  
- IntegraÃ§Ã£o entre Pandas e Spark  
- OrganizaÃ§Ã£o modular do cÃ³digo  

- Site oficial: https://www.python.org/

---

### Java (JDK 17)
Utilizado como dependÃªncia obrigatÃ³ria para execuÃ§Ã£o do Apache Spark.  
O projeto foi configurado para rodar com **Java 17 (LTS)**, garantindo compatibilidade e estabilidade.

- Download: https://adoptium.net/
- DocumentaÃ§Ã£o: https://docs.oracle.com/en/java/javase/17/

---

### Delta + Spark no Windows
Ambiente local configurado no Windows para desenvolvimento e testes do pipeline ETL.

Componentes-chave:
- VariÃ¡veis de ambiente (`JAVA_HOME`, `PATH`)
- Spark compatÃ­vel com Java 17
- ExecuÃ§Ã£o local (standalone)

---

## ğŸ”— Links Ãšteis

- Apache Spark: https://spark.apache.org/
- Delta Lake: https://delta.io/
- Pandas: https://pandas.pydata.org/
- Parquet: https://parquet.apache.org/
- Python: https://www.python.org/
- Java 17 (Eclipse Temurin): https://adoptium.net/


## Diagrama Ilustrativo via Excalidraw

![Diagrama do projeto](docs/diagrama_ilustrativo_ipca_boi.png)

## Diagrama conceitual:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Source â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ XLS (CEPEA)  â”‚
â”‚ API (BCB)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Landing         â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ XLS â†’ CSV Padronizadoâ”‚
â”‚ Manifest (SHA-256)   â”‚
â”‚ Dedupe / Auditoria   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bronze (Delta Lake)  â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚     Dados crus       |
â”‚  Linhagem completa   â”‚
â”‚   PartiÃ§Ã£o ano/mÃªs   â”‚
â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Silver (Delta Lake)  â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ NormalizaÃ§Ã£o         â”‚
â”‚ Regras de negÃ³cio    â”‚
â”‚ Qualidade aplicada   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gold (Analytics)     â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ MÃ©tricas econÃ´micas  â”‚
â”‚ VariaÃ§Ãµes mensais    â”‚
â”‚ Insights             â”‚
â”‚ Views para BI        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
---

 *Este projeto faz parte de um pipeline ETL para ingestÃ£o, padronizaÃ§Ã£o e rastreabilidade de dados econÃ´micos, com foco em escalabilidade e governanÃ§a.*


## Diagrama de Fluxo do Pipeline:

```
[Ingest XLS]
     |
     |-- calcula SHA-256
     |-- verifica manifest
     |-- converte XLS â†’ CSV
     |-- registra manifest
     |
     v
   [CSV ]
     |
     |-- Spark lÃª CSV
     |-- join com manifest
     |-- adiciona colunas tÃ©cnicas
     |-- validaÃ§Ãµes mÃ­nimas
     |
     v
[Bronze Delta]
     |
     |-- 
     |-- partiÃ§Ã£o ano/mÃªs
     |
     v
[Silver Delta]
     |
     |-- normalizaÃ§Ã£o
     |-- joins temporais
     |
     v
[Gold AnalÃ­tico]
     |
     |-- mÃ©tricas globais
     |-- regras econÃ´micas
     |
     v
[View para Dashboard]
```


## ğŸ‘¤ Autor

**Daniel Martins FranÃ§a**  

*Projeto desenvolvido com foco em **engenharia de dados**, aplicando boas prÃ¡ticas de ETL, versionamento de dados e arquitetura em camadas (Bronze).*

---

